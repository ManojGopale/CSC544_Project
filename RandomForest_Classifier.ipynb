{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle, gzip, numpy\n",
    "\n",
    "## Load the dataset\n",
    "f = gzip.open('./mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_setSize= (50000, 784), train_set_labels= (50000,), <type 'numpy.ndarray'>\n",
      "X_train= (50000, 784), <type 'numpy.ndarray'>\n",
      "Y_train= (50000,), <type 'numpy.ndarray'>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print \"train_setSize= %s, train_set_labels= %s, %s\" \\\n",
    "%(train_set[0].shape, train_set[1].shape,  type(train_set[0]))\n",
    "\n",
    "## The cPickle method returns tuple with training cases and labels. \n",
    "## We need to extract them form these\n",
    "\n",
    "X_train = train_set[0][:]\n",
    "Y_train = train_set[1][:]\n",
    "\n",
    "\n",
    "print (\"X_train= %s, %s\\nY_train= %s, %s\\n\") \\\n",
    "%(X_train.shape, type(X_train), Y_train.shape, type(Y_train))\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid= (10000, 784), <type 'numpy.ndarray'>\n",
      "Y_valid= (10000,), <type 'numpy.ndarray'>\n",
      "\n",
      "Score on Valid set= 0.950700\n"
     ]
    }
   ],
   "source": [
    "## Validating the model\n",
    "X_valid = valid_set[0]\n",
    "Y_valid = valid_set[1]\n",
    "\n",
    "print \"X_valid= %s, %s\\nY_valid= %s, %s\\n\" \\\n",
    "%(X_valid.shape, type(X_valid), Y_valid.shape, type(Y_valid))\n",
    "\n",
    "## Score of the trained data set on the validation set\n",
    "score = clf.score(X_valid, Y_valid)\n",
    "\n",
    "print \"Score on Valid set= %f\" %(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test= (10000, 784), <type 'numpy.ndarray'>\n",
      "Y_test= (10000,), <type 'numpy.ndarray'>\n",
      "\n",
      "Score on Test data= 0.946600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get score on the test data\n",
    "X_test = test_set[0]\n",
    "Y_test = test_set[1]\n",
    "\n",
    "print \"X_test= %s, %s\\nY_test= %s, %s\\n\"\\\n",
    "%(X_test.shape, type(X_test), Y_test.shape, type(Y_test) )\n",
    "\n",
    "scoreTest = clf.score(X_test, Y_test)\n",
    "\n",
    "print \"Score on Test data= %f\\n\" %(scoreTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probTest = [[ 0.   0.   0.  ...,  1.   0.   0. ]\n",
      " [ 0.   0.   0.9 ...,  0.   0.   0. ]\n",
      " [ 0.   1.   0.  ...,  0.   0.   0. ]\n",
      " ..., \n",
      " [ 0.   0.   0.  ...,  0.1  0.1  0.1]\n",
      " [ 0.   0.1  0.  ...,  0.   0.3  0. ]\n",
      " [ 0.   0.   0.  ...,  0.   0.   0. ]], shape= (10000, 10)\n",
      "\n",
      "probTest[0]= [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.], len= 10\n",
      "\n",
      "Predicted Class= 5, True Class= 5\n",
      "Class\tProbability\n",
      "0\t0.200000\n",
      "1\t0.000000\n",
      "2\t0.000000\n",
      "3\t0.000000\n",
      "4\t0.000000\n",
      "5\t0.500000\n",
      "6\t0.100000\n",
      "7\t0.000000\n",
      "8\t0.100000\n",
      "9\t0.100000\n"
     ]
    }
   ],
   "source": [
    "## getting probabilities for each test data\n",
    "\n",
    "probTest = clf.predict_proba(X_test)\n",
    "\n",
    "print \"probTest = %s, shape= %s\\n\" %(probTest, probTest.shape)\n",
    "\n",
    "print \"probTest[0]= %s, len= %d\\n\" %(probTest[0], len(probTest[0]))\n",
    "\n",
    "## index\n",
    "index= 1089\n",
    "## Predicted class\n",
    "yPredictTest = clf.predict(X_test)\n",
    "print \"Predicted Class= %d, True Class= %d\" %(yPredictTest[index], Y_test[index])\n",
    "\n",
    "print \"Class\\tProbability\"\n",
    "for i in range(len(probTest[index])):\n",
    "    print \"%d\\t%f\" %(i, probTest[index][i])\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
